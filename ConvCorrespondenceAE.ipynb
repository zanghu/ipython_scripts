{
 "metadata": {
  "name": "ConvCorrespondenceAE"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylearn2.costs.cost import Cost, SumOfCosts\n",
      "from pylearn2.space import VectorSpace, Conv2DSpace\n",
      "from collections import OrderedDict\n",
      "from itertools import izip\n",
      "import sys\n",
      "\n",
      "import numpy\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "\n",
      "from pylearn2.models.model import Model\n",
      "from pylearn2.base import Block\n",
      "from pylearn2.utils import sharedX\n",
      "from pylearn2.models.mlp import ConvRectifiedLinear, MLP\n",
      "#from my_mlp import ConvRectifiedLinear, MLP\n",
      "from multi_AE_0226 import AdjustableMultimodalAutoEncoder, MyMultimodalAutoEncoder\n",
      "from multi_AE_0226 import CorreCost, CombineCrossEntropyCost, AdjustableCombineCrossEntropyCost, CrossModalCrossEntropyCost\n",
      "\n",
      "theano.config.compute_test_value = 'off'\n",
      "\n",
      "class SpecialCost(Cost):\n",
      "    \n",
      "    def expr(self, model, data, **kwargs):\n",
      "        \"\"\"\"\"\"\n",
      "        return None\n",
      "    \n",
      "    def get_gradients(self, model, data, **kwargs):\n",
      "        \"\"\"\"\"\"\n",
      "        #\u4e24\u90e8\u5206\u4ee3\u4ef7\n",
      "        assert data.ndim == 2\n",
      "        AE_cost = AdjustableCombineCrossEntropyCost(img_dim=model.multi_AE.n_vis_img, txt_dim=model.multi_AE.n_vis_txt)\n",
      "        corre_cost = CorreCost(img_dim=model.multi_AE.n_vis_img, txt_dim=model.multi_AE.n_vis_txt)\n",
      "        \n",
      "        #AE_cost\u53ea\u5173\u4e8eAE\u7684\u53c2\u6570\u6c42\u5bfc\uff0ccorre_cost\u65e2\u5173\u4e8eAE\u7684\u53c2\u6570\u6709\u5173\u4e0emlp\u7684\u53c2\u6570\u6c42\u5bfc\n",
      "        print 'in get_gradients, model.mlp_left.nvis=', model.mlp_left.get_input_space().get_total_dimension()\n",
      "        print 'in get_gradients, model.mlp_right.nvis=', model.mlp_right.get_input_space().get_total_dimension()\n",
      "        \n",
      "        #orin_data_left = data[:, :model.mlp_left.get_input_space().get_total_dimension()]\n",
      "        #orin_data_right = data[:, model.mlp_left.get_input_space().get_total_dimension(): \\\n",
      "        #                     model.mlp_left.get_input_space().get_total_dimension() + model.mlp_right.get_input_space().get_total_dimension()]\n",
      "        #\u5bf9\u8bbe\u8ba1\u77e9\u9635\u8fdb\u884c\u5207\u5206\n",
      "        orin_data_left = data[:, :392]\n",
      "        orin_data_right = data[:, 392: 784]\n",
      "        #\u5c06VectorSpace\u7684\u8f93\u5165\u8f6c\u6362\u4e3aConv2DSpace\u7684\u8f93\u5165\n",
      "        mlp_left_input = VectorSpace(dim=392).format_as(orin_data_left, model.mlp_left.get_input_space())\n",
      "        mlp_right_input = VectorSpace(dim=392).format_as(orin_data_right, model.mlp_right.get_input_space())\n",
      "        \n",
      "        print 'mlp_left_input.ndim=%d' % mlp_left_input.ndim\n",
      "        print 'mlp_right_input.ndim=%d'% mlp_right_input.ndim\n",
      "        \n",
      "        assert mlp_left_input.ndim == 4\n",
      "        assert mlp_right_input.ndim == 4\n",
      "        \n",
      "        mlp_left_output = model.mlp_left.fprop(mlp_left_input)\n",
      "        mlp_right_output = model.mlp_right.fprop(mlp_right_input)\n",
      "        \n",
      "        assert mlp_left_output.ndim == 4\n",
      "        assert mlp_right_output.ndim == 4\n",
      "        \n",
      "        #print \"test 3...\"\n",
      "        #sys.stdout.flush()\n",
      "        data_AE_left_in = model.mlp_left.get_output_space().format_as(mlp_left_output, model.multi_AE.img_AE.get_input_space())\n",
      "        data_AE_right_in = model.mlp_right.get_output_space().format_as(mlp_right_output, model.multi_AE.txt_AE.get_input_space())\n",
      "        assert data_AE_left_in.ndim == 2\n",
      "        assert data_AE_right_in.ndim == 2\n",
      "        data_AE_in = T.concatenate([data_AE_left_in, data_AE_right_in], axis=1)\n",
      "        #print \"test 4...\"\n",
      "        assert data_AE_in.ndim == 2\n",
      "        \n",
      "        multi_AE_gradients, update_AE = SumOfCosts([AE_cost, corre_cost]).get_gradients(model=model.multi_AE, data=data_AE_in)\n",
      "        #multi_AE_gradients, update_AE = AE_cost.get_gradients(model=model.multi_AE, data=data_AE_in)\n",
      "        \n",
      "        corre_cost_expr = corre_cost.expr(model=model.multi_AE, data=data_AE_in) #\u6ce8\u610f\u8be5\u7b26\u53f7\u8868\u8fbe\u5f0f\u4e2d\u542b\u6709mlp\u7684\u53c2\u6570\n",
      "        mlp_params_left = list(model.mlp_left.get_params())\n",
      "        mlp_params_right = list(model.mlp_right.get_params())\n",
      "        mlp_params = mlp_params_left + mlp_params_right #\u5de6\u53f3\u4e24\u4e2amlp\u53c2\u6570\u5217\u8868\n",
      "        mlp_grads = T.grad(corre_cost_expr, mlp_params, disconnected_inputs='ignore') #\u68af\u5ea6\u5217\u8868\n",
      "        mlp_gradients = OrderedDict(izip(mlp_params, mlp_grads)) #\u53c2\u6570\u5217\u8868\u4e0e\u68af\u5ea6\u5217\u8868\u5bf9\u5e94\u8d77\u6765\u7ec4\u6210\u5b57\u5178\n",
      "        \n",
      "        gradients = OrderedDict()\n",
      "        gradients.update(multi_AE_gradients)\n",
      "        gradients.update(mlp_gradients)\n",
      "        updates = OrderedDict()\n",
      "        updates.update(update_AE)\n",
      "        \n",
      "        return gradients, updates\n",
      "        \n",
      "    def get_data_specs(self, model):\n",
      "        \"\"\"\"\"\"\n",
      "        return model.get_monitoring_data_specs()\n",
      "\n",
      "class ConvMultimodalAutoEncoder(Model, Block):\n",
      "    \"\"\"\u62e5\u6709\u4e24\u4e2aMLP\u5bf9\u8c61\u4f55\u4e00\u4e2aAdjustableMultimodalAutoEncoder\u5bf9\u8c61\"\"\"\n",
      "    def __init__(self, mlp_left, mlp_right, multi_AE, mlp_lr_scale=0.1, numpy_rng=None, theano_rng=None):\n",
      "        \"\"\"\u8bbe\u8ba1\u5047\u8bbe\u4e09\u4e2a\u81ea\u6478\u578b\u5df2\u7ecf\u5206\u522b\u521d\u59cb\u5316\u5b8c\u6210\uff0c\u76f4\u63a5\u4f5c\u4e3a\u53c2\u6570\u8f93\u5165\uff0c\u4f5c\u4e3a\u5c5e\u6027\"\"\"\n",
      "        Model.__init__(self) # self.names_to_del = set(); self._test_batch_size = 2\n",
      "        Block.__init__(self) # self.fn = None; self.cpu_only = False\n",
      "        \n",
      "        for m in [mlp_left, mlp_right]:\n",
      "            assert isinstance(m, MLP)\n",
      "            for layer in m.layers:\n",
      "                assert isinstance(layer, ConvRectifiedLinear) #\u8981\u6c42MLP\u5bf9\u8c61\u7684\u6bcf\u4e00\u5c42\u90fd\u662f\u5377\u79ef\u7f51\u7edc\n",
      "                \n",
      "        assert isinstance(mlp_lr_scale, float) #\u53c2\u6570\u7c7b\u578b\u68c0\u67e5\n",
      "        self.mlp_lr_scale = sharedX(mlp_lr_scale) #\u76f4\u63a5\u5c06self.mlp_lr_scale\u8fdb\u884cshared\u5316\n",
      "        \n",
      "        assert isinstance(multi_AE, AdjustableMultimodalAutoEncoder)\n",
      "        #\u68c0\u67e5\u4e0b\u5c42\u7684\u8f93\u51fa\u7ef4\u6570\u662f\u5426\u7b49\u4e8e\u4e0a\u5c42\u7684\u8f93\u5165\u7ef4\u6570\n",
      "        #print 'mlp: ', mlp_left.get_output_space().get_total_dimension()\n",
      "        #print 'AE: ', multi_AE.n_vis_img\n",
      "        assert mlp_left.get_output_space().get_total_dimension() == multi_AE.n_vis_img #\u5de6\u4fa7mlp\u5bf9img\n",
      "        assert mlp_right.get_output_space().get_total_dimension() == multi_AE.n_vis_txt #\u53f3\u4fa7mlp\u5bf9txt\n",
      "        \n",
      "        self.mlp_left = mlp_left\n",
      "        self.mlp_right = mlp_right\n",
      "        self.multi_AE = multi_AE\n",
      "        \n",
      "        #self.mlp_left.nvis = self.mlp_left.get_input_space().get_total_dimension()\n",
      "        #self.mlp_right.nvis = self.mlp_right.get_input_space().get_total_dimension()\n",
      "\n",
      "        input_dim = self.mlp_left.get_input_space().get_total_dimension() + self.mlp_right.get_input_space().get_total_dimension()\n",
      "        #self.input_space = Conv2DSpace(shape=[28, 28], num_channels=1) # add input_space\n",
      "        self.input_space = VectorSpace(dim=input_dim) # add input_space\n",
      "        self.output_space = VectorSpace(dim=self.multi_AE.n_hid) # add output_space\n",
      "        \n",
      "        #\u53c2\u6570\u987a\u5e8f\uff1a\u56fe\u50cf\u6743\u503c\u77e9\u9635\uff0c \u56fe\u50cf\u7f16\u7801\u504f\u7f6e\uff0c\u56fe\u50cf\u89e3\u7801\u504f\u7f6e\uff0c\u6587\u672c\u6743\u503c\u77e9\u9635\uff0c\u6587\u672c\u7f16\u7801\u504f\u7f6e\uff0c\u6587\u672c\u89e3\u7801\u504f\u7f6e\n",
      "        self._params = list(set.union(set(self.mlp_left.get_params()), set(self.mlp_right.get_params()), set(self.multi_AE.get_params())))\n",
      "        \n",
      "    def get_monitoring_data_specs(self):\n",
      "        \"\"\"\"\"\"\n",
      "        return (self.get_input_space(), self.get_input_source())\n",
      "    \n",
      "    def get_monitoring_channels(self, data):\n",
      "        \"\"\"\"\"\"\n",
      "        channels = OrderedDict()\n",
      "        \n",
      "        #\u5bf9\u8bbe\u8ba1\u77e9\u9635\u8fdb\u884c\u5207\u5206\n",
      "        orin_data_left = data[:, :392]\n",
      "        orin_data_right = data[:, 392: 784]\n",
      "        #\u5c06VectorSpace\u7684\u8f93\u5165\u8f6c\u6362\u4e3aConv2DSpace\u7684\u8f93\u5165\n",
      "        mlp_left_input = VectorSpace(dim=392).format_as(orin_data_left, self.mlp_left.get_input_space())\n",
      "        mlp_right_input = VectorSpace(dim=392).format_as(orin_data_right, self.mlp_right.get_input_space())\n",
      "        \n",
      "        assert mlp_left_input.ndim == 4\n",
      "        assert mlp_right_input.ndim == 4\n",
      "        \n",
      "        mlp_left_output = self.mlp_left.fprop(mlp_left_input)\n",
      "        mlp_right_output = self.mlp_right.fprop(mlp_right_input)\n",
      "        \n",
      "        assert mlp_left_output.ndim == 4\n",
      "        assert mlp_right_output.ndim == 4\n",
      "\n",
      "        data_AE_left_in = self.mlp_left.get_output_space().format_as(mlp_left_output, self.multi_AE.img_AE.get_input_space())\n",
      "        data_AE_right_in = self.mlp_right.get_output_space().format_as(mlp_right_output, self.multi_AE.txt_AE.get_input_space())\n",
      "        data_AE_in = T.concatenate([data_AE_left_in, data_AE_right_in], axis=1)\n",
      "        \n",
      "        img_data = data_AE_left_in\n",
      "        txt_data = data_AE_right_in\n",
      "        \n",
      "        code_img = self.multi_AE.img_AE.get_train_enc(img_data) #\u56fe\u50cf\u7aef\u7f16\u7801\n",
      "        code_txt = self.multi_AE.txt_AE.get_train_enc(txt_data) #\u6587\u672c\u7aef\u7f16\u7801\n",
      "        img2img = self.multi_AE.img_AE.get_dec(code_img) #\u56fe\u50cf\u6062\u590d\u56fe\u50cf\n",
      "        txt2txt = self.multi_AE.txt_AE.get_dec(code_txt) #\u6587\u672c\u6062\u590d\u6587\u672c\n",
      "        \n",
      "        channel_name = 'img2img_recon_error'\n",
      "        img2img_recon_error = (T.square(img2img - img_data).sum(axis=1)).mean()\n",
      "        channels[channel_name] = img2img_recon_error\n",
      "        #self.model_type: 'Combine', 'FullModal'\n",
      "        channel_name = 'txt2txt_recon_error'\n",
      "        txt2txt_recon_error = (T.square(txt2txt - txt_data).sum(axis=1)).mean()\n",
      "        channels[channel_name] = txt2txt_recon_error\n",
      "        \n",
      "        channel_name = 'corre_cost'\n",
      "        corre_cost = T.mean(T.sum(T.square(code_img - code_txt), axis=1), axis=0)\n",
      "        channels[channel_name] = corre_cost\n",
      "        \n",
      "        return channels\n",
      "    \n",
      "    def get_default_cost(self):\n",
      "        \"\"\"\"\"\"\n",
      "        return SpecialCost()\n",
      "    \n",
      "    def censor_updates(self, updates):\n",
      "        \"\"\"\"\"\"\n",
      "        pass\n",
      "    \n",
      "    def get_lr_scalers(self):\n",
      "        \"\"\"\"\"\"\n",
      "        rval = OrderedDict()\n",
      "        return rval\n",
      "    \n",
      "    def setup_mlp_lr_scale(self):\n",
      "        \"\"\"\u964d\u4f4e\u5e95\u5c42mlp\u7684\u53c2\u6570\u5b66\u4e60\u901f\u7387\"\"\"\n",
      "        #\u6ce8\u610f\u5230\u7531\u4e8eself.mlp_lr_scale\u5df2\u7ecf\u662fshared\u578b\uff0c\u56e0\u6b64\u5982\u4e0b\u8d4b\u503c\u540e\u5404\u5c42\u53c2\u6570\u7684lr_scale\u4e5f\u662fshared\u578b\n",
      "        for layer in self.left_mlp.layers():\n",
      "            layer.W_lr_scale = self.mlp_lr_scale\n",
      "            layer.b_lr_scale = self.mlp_lr_scale\n",
      "            \n",
      "        for layer in self.right_mlp.layers():\n",
      "            layer.W_lr_scale = self.mlp_lr_scale\n",
      "            layer.b_lr_scale = self.mlp_lr_scale\n",
      "        \n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    \n",
      "    from pylearn2.datasets.mnist import MNIST\n",
      "    from pylearn2.space import Conv2DSpace\n",
      "    from pylearn2.training_algorithms.sgd import SGD\n",
      "    from pylearn2.costs.cost import SumOfCosts\n",
      "    from pylearn2.train import Train\n",
      "    #from pylearn2.training_algorithms.sgd import MonitorBasedLRAdjuster\n",
      "    #from pylearn2.training_algorithms.sgd import MomentumAdjustor\n",
      "    from pylearn2.termination_criteria import EpochCounter\n",
      "    \n",
      "    dsm_train = MNIST(which_set='train', start=0, stop=500, one_hot=True)\n",
      "    dsm_valid = MNIST(which_set='train', start=500, stop=600, one_hot=True)\n",
      "    dsm_test = MNIST(which_set='test', start=0, stop=100, one_hot=True)\n",
      "    \n",
      "    monitoring_dataset = {'train': dsm_train, 'valid': dsm_valid, 'test': dsm_test}\n",
      "    #monitoring_dataset = {'train': dsm_train}\n",
      "\t\n",
      "    ae_model = AdjustableMultimodalAutoEncoder(model_type='Combine', alpha=0.5, beta=0.5, n_vis_img=2816, n_vis_txt=2816, n_hid_img=100, n_hid_txt=100)\n",
      "    \n",
      "    crl_layer_left = ConvRectifiedLinear(layer_name='mlp_left', output_channels=64, irange=0.05, \n",
      "                                kernel_shape=[5, 5], kernel_stride=(1, 1), pool_shape=[4, 4], pool_stride=[2, 2], max_kernel_norm=1.9365)\n",
      "    crl_layer_right = ConvRectifiedLinear(layer_name='mlp_right', output_channels=64, irange=0.05, \n",
      "                                kernel_shape=[5, 5], kernel_stride=(1, 1), pool_shape=[4, 4], pool_stride=[2, 2], max_kernel_norm=1.9365)\n",
      "    \n",
      "    mlp_left = MLP(input_space=Conv2DSpace(shape=[28, 14], num_channels=1), layers=[crl_layer_left])\n",
      "    mlp_right = MLP(input_space=Conv2DSpace(shape=[28, 14], num_channels=1), layers=[crl_layer_right])\n",
      "    \n",
      "    conv_ae_model = ConvMultimodalAutoEncoder(mlp_left=mlp_left, mlp_right=mlp_right, multi_AE=ae_model)\n",
      "    \n",
      "    alg = SGD(learning_rate=0.01, cost=None, batch_size=20, init_momentum=None, monitoring_dataset=monitoring_dataset,\n",
      "              termination_criterion=EpochCounter(max_epochs=15))\n",
      "    \n",
      "    train = Train(dataset=dsm_train, model=conv_ae_model, algorithm=alg, save_path='ae_save.pkl', save_freq=5)\n",
      "    \n",
      "    train.main_loop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Input shape:  (28, 14)\n",
        "Detector space:  (24, 10)\n",
        "Output space: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (11, 4)\n",
        "Input shape:  (28, 14)\n",
        "Detector space:  (24, 10)\n",
        "Output space: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (11, 4)\n",
        "in get_gradients, model.mlp_left.nvis="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 392\n",
        "in get_gradients, model.mlp_right.nvis= 392\n",
        "mlp_left_input.ndim=4\n",
        "mlp_right_input.ndim=4\n",
        "Parameter and initial learning rate summary:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tb_enc: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tW: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tb_dec: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tb: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tW: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tb_dec: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tW: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tb: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tW: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tb_enc: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Compiling sgd_update...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Compiling sgd_update done. Time elapsed: 10.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compiling begin_record_entry...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "compiling begin_record_entry done. Time elapsed: 0.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitored channels: \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Compiling accum...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "graph size: 119\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "graph size: 117\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "graph size: 117\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Compiling accum done. Time elapsed: 8.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 0.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 1.79101720697\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 648.665114439\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 641.329670318\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 1.88904820875\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 644.37919908\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 638.08403438\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 1.88753185682\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 642.132744341\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 635.197263062\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 25\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.0700787510986\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 166.222438158\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 172.76745947\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.0773556610596\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 166.092300994\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 173.152094632\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.0803845265942\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 166.045409763\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 173.47464027\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 50\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 1000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.0429518108817\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 36.3817061213\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 33.2037051847\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.0331062052013\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 36.0153132789\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 33.2726765844\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.0329561405448\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 36.0625710017\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 33.27057808\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 75\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 1500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.00739916639553\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 10.6134021447\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 10.861121743\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.00866132683738\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 10.5772425158\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 10.8786931442\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.0083076871145\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 10.6026854458\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 10.8699067797\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 100\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 2000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.00725221312262\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 4.77037110662\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 4.58847633087\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.00653728299568\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 4.75445665585\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 4.57955486152\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.00734942478025\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 4.7693041957\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 4.58219816422\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 5\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 125\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 2500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.00628517671756\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 2.45691368268\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 2.51822121248\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.00630717574169\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 2.449440374\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 2.51111286922\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.00593643736331\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 2.45520159289\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 2.50978754442\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving to ae_save.pkl...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving to ae_save.pkl done. Time elapsed: 0.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 6\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 150\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 3000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.00365819086562\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 1.51568391628\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 1.49305099999\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.00368207192116\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 1.51291133967\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 1.48849957512\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.00440533591821\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 1.51610235042\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 1.4880141988\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 7\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 175\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 3500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.00312811934534\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 0.997908654395\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 1.00072572573\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.00272399917814\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 0.996204269524\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 0.996213371365\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.00256885091854\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 0.997704640419\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 0.995279480713\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 8\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 200\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 4000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.00194126545791\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 0.700910685082\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 0.700419697651\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.00195682501516\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 0.69967498989\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 0.698068557006\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.002385412873\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 0.700820718513\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 0.698379335866\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 9\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 225\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 4500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.00141245237631\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 0.52250907824\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 0.518440300826\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.00113004962529\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 0.521120027035\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 0.515528793211\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.00106961651638\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 0.522121590037\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 0.515142260555\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 10\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 250\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 5000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.000986985527513\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 0.394236509929\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 0.396738887166\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.000966630063172\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 0.393293279194\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 0.395299746724\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.00126539262674\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 0.394075098322\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 0.395621762097\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving to ae_save.pkl...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving to ae_save.pkl done. Time elapsed: 0.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 11\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 275\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 5500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.00110207760414\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 0.318038679807\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 0.310592062322\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.000975015845324\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 0.317328487863\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 0.309153048055\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.000938082695744\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 0.31798790988\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 0.309451992382\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 12\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 300\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 6000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.000968332871773\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 0.249523519091\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 0.254202171298\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.000919408324485\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 0.248968786447\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 0.25316242365\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.00116869485491\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 0.249477957054\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 0.253459144731\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 13\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 325\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 6500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.000785245779149\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 0.21191533211\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 0.205738295064\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.000677152475096\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 0.211401607736\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 0.20475731589\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.000656131854267\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 0.211819080584\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 0.204994882619\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 14\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 350\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 7000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.000623847972059\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 0.170940080075\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 0.175641149955\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.000626068158218\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 0.170638682041\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 0.174833593935\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.000807203189121\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 0.171023835402\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 0.174995957238\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Time this epoch: 2.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monitoring step:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tEpochs seen: 15\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tBatches seen: 375\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tExamples seen: 7500\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tlearning_rate: 0.01\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tmonitor_seconds_per_epoch: 2.0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_corre_cost: 0.000785605692452\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_img2img_recon_error: 0.154909290958\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttest_txt2txt_recon_error: 0.145067338091\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_corre_cost: 0.000735732407834\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_img2img_recon_error: 0.15424714656\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\ttrain_txt2txt_recon_error: 0.144573225644\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_corre_cost: 0.000721822944663\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_img2img_recon_error: 0.154720834413\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\tvalid_txt2txt_recon_error: 0.144798232219\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving to ae_save.pkl...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving to ae_save.pkl done. Time elapsed: 0.000000 seconds\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving to ae_save.pkl...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Saving to ae_save.pkl done. Time elapsed: 0.000000 seconds\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " import numpy\n",
      "print numpy.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.8.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u6d4b\u8bd5Downsample\n",
      "from pylearn2.datasets.preprocessing import Downsample\n",
      "\n",
      "preprocessor = Downsample(sampling_factor=[2,2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dataset_from_design import DatasetFromDesign\n",
      "from pylearn2.datasets.preprocessing import Downsample\n",
      "from pylearn2.datasets.dense_design_matrix import DefaultViewConverter\n",
      "import numpy\n",
      "\n",
      "print 'loading...'\n",
      "f1 = open('/home/zanghu/Pro_Datasets/feret_55/feret_train55_X.npy')\n",
      "f2 = open('/home/zanghu/Pro_Datasets/feret_55/feret_test55_X.npy')\n",
      "f3 = open('/home/zanghu/Pro_Datasets/feret_55/feret_train55_label.npy')\n",
      "f4 = open('/home/zanghu/Pro_Datasets/feret_55/feret_train55_label.npy')\n",
      "\n",
      "X_train = numpy.array(numpy.load(f1), dtype=float)\n",
      "X_test = numpy.array(numpy.load(f2), dtype=float)\n",
      "y_train = numpy.array(numpy.load(f3), dtype=float)\n",
      "y_test = numpy.array(numpy.load(f4), dtype=float)\n",
      "\n",
      "f1.close()\n",
      "f2.close()\n",
      "f3.close()\n",
      "f4.close()\n",
      "\n",
      "print 'making dataset...'\n",
      "view_converter = DefaultViewConverter([80, 80, 1], axes=('b', 0, 1, 'c'))\n",
      "#\u4ee5\u4e0b\u5236\u9020\u6570\u636e\u96c6\u65f6\u52a0\u5165cnter\u5316\n",
      "dsf_train = DatasetFromDesign(design_matrix=X_train-127.5, labels=y_train, view_converter=view_converter)\n",
      "dsf_test = DatasetFromDesign(design_matrix=X_test-127.5, labels=y_test, view_converter=view_converter)\n",
      "\n",
      "\n",
      "print 'sampling...'\n",
      "preprocessor = Downsample(sampling_factor=[2, 2])\n",
      "dsf_train.apply_preprocessor(preprocessor)\n",
      "dsf_test.apply_preprocessor(preprocessor)\n",
      "print 'dsf_tran.shape=', dsf_train.X.shape #(700, 1600), \u7ecf\u8fc7\u5377\u79ef\u62bd\u6837\u540e\uff0c\u6bcf\u5f20\u56fe\u7247\u5927\u5c0f\u53d8\u4e3a40*40=1600\n",
      "print 'dsf_test.shape=', dsf_test.X.shape #(700, 1600), \u7ecf\u8fc7\u5377\u79ef\u62bd\u6837\u540e\uff0c\u6bcf\u5f20\u56fe\u7247\u5927\u5c0f\u53d8\u4e3a40*40=1600\n",
      "\n",
      "import cPickle\n",
      "f = open('/home/zanghu/feret55_train_X_sampled.pkl', 'w')\n",
      "cPickle.dump(dsf_train, f, protocol=2)\n",
      "f.close()\n",
      "f = open('/home/zanghu/feret55_test_X_sampled.pkl', 'w')\n",
      "cPickle.dump(dsf_test, f, protocol=2)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading...\n",
        "making dataset..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "sampling...\n",
        "dsf_tran.shape="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (700, 1600)\n",
        "dsf_test.shape= (700, 1600)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == '__main__':  \n",
      "    from conv_multi_ae_test import ConvMultimodalAutoEncoder, SpecialCost\n",
      "    from multi_AE_0226 import AdjustableMultimodalAutoEncoder, MyMultimodalAutoEncoder\n",
      "    from multi_AE_0226 import CorreCost, CombineCrossEntropyCost, AdjustableCombineCrossEntropyCost, CrossModalCrossEntropyCost\n",
      "\n",
      "    from load_pylearn2_dataset import load_pylearn2_feret55_sampled\n",
      "    from pylearn2.models.mlp import MLP, ConvRectifiedLinear\n",
      "    from pylearn2.space import Conv2DSpace\n",
      "    from pylearn2.training_algorithms.sgd import SGD\n",
      "    from pylearn2.costs.cost import SumOfCosts\n",
      "    from pylearn2.train import Train\n",
      "    from pylearn2.training_algorithms.sgd import MonitorBasedLRAdjuster\n",
      "    #from pylearn2.training_algorithms.sgd import MomentumAdjustor\n",
      "    from pylearn2.termination_criteria import EpochCounter\n",
      "    \n",
      "    #\u4f7f\u7528\u8bfb\u53d6\u51fd\u6570\u76f4\u63a5\u8bfb\u53d6\u6307\u5b9a\u6570\u636e\u96c6\n",
      "    dsf_train = load_pylearn2_feret55_sampled(which_set='train')\n",
      "    dsf_test = load_pylearn2_feret55_sampled(which_set='test')\n",
      "    \n",
      "    monitoring_dataset = {'train': dsf_train, 'test': dsf_test}\n",
      "    #monitoring_dataset = {'train': dsf_train}\n",
      "\t\n",
      "    ae_model = AdjustableMultimodalAutoEncoder(model_type='Combine', alpha=0.5, beta=0.5, n_vis_img=1248, n_vis_txt=1248, n_hid_img=1000, n_hid_txt=1000)\n",
      "    \n",
      "    crl_layer_left_h1 = ConvRectifiedLinear(layer_name='mlp_left_h1', output_channels=64, irange=0.05, \n",
      "                                kernel_shape=[5, 5], pool_shape=[4, 4], pool_stride=[2, 2], max_kernel_norm=1.9365)\n",
      "    crl_layer_left_h2 = ConvRectifiedLinear(layer_name='mlp_left_h2', output_channels=64, irange=0.05, \n",
      "                                kernel_shape=[4, 4], pool_shape=[2, 2], pool_stride=[1, 1], max_kernel_norm=1.9365)\n",
      "    crl_layer_right_h1 = ConvRectifiedLinear(layer_name='mlp_right_h1', output_channels=64, irange=0.05, \n",
      "                                kernel_shape=[5, 5], pool_shape=[4, 4], pool_stride=[2, 2], max_kernel_norm=1.9365)\n",
      "    crl_layer_right_h2 = ConvRectifiedLinear(layer_name='mlp_right_h2', output_channels=64, irange=0.05, \n",
      "                                kernel_shape=[4, 4], pool_shape=[2, 2], pool_stride=[1, 1], max_kernel_norm=1.9365)\n",
      "    \n",
      "    mlp_left = MLP(input_space=Conv2DSpace(shape=[40, 20], num_channels=1), layers=[crl_layer_left_h1, crl_layer_left_h2])\n",
      "    mlp_right = MLP(input_space=Conv2DSpace(shape=[40, 20], num_channels=1), layers=[crl_layer_right_h1, crl_layer_right_h2])\n",
      "    \n",
      "    conv_ae_model = ConvMultimodalAutoEncoder(mlp_left=mlp_left, mlp_right=mlp_right, multi_AE=ae_model)\n",
      "    \n",
      "    alg = SGD(learning_rate=0.01, cost=None, batch_size=20, init_momentum=None, monitoring_dataset=monitoring_dataset,\n",
      "              termination_criterion=EpochCounter(max_epochs=15))\n",
      "    \n",
      "    train = Train(dataset=dsf_train, model=conv_ae_model, algorithm=alg, save_path='ae_save.pkl', save_freq=5)\n",
      "    \n",
      "    train.main_loop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Input shape:  (40, 20)\n",
        "Detector space:  (36, 16)\n",
        "Output space: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (17, 7)\n",
        "Input shape:  (17, 7)\n",
        "Detector space:  (14, 4)\n",
        "Output space: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (13, 3)\n",
        "Input shape:  (40, 20)\n",
        "Detector space:  (36, 16)\n",
        "Output space: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (17, 7)\n",
        "Input shape:  (17, 7)\n",
        "Detector space:  (14, 4)\n",
        "Output space: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (13, 3)\n",
        "mlp_left:  2496\n",
        "AE.n_vis_img:  1248\n",
        "mlp_right:  2496\n",
        "AE.n_vis_txt:  1248\n"
       ]
      },
      {
       "ename": "AssertionError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-60c3e85d5962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmlp_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConv2DSpace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrl_layer_right_h1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrl_layer_right_h2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mconv_ae_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvMultimodalAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_left\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp_right\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_AE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mae_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     alg = SGD(learning_rate=0.01, cost=None, batch_size=20, init_momentum=None, monitoring_dataset=monitoring_dataset,\n",
        "\u001b[0;32m/home/zanghu/ipy_notebook/conv_multi_ae_test.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mlp_left, mlp_right, multi_AE, numpy_rng, theano_rng)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'AE.n_vis_txt: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vis_txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mmlp_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_total_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmulti_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vis_img\u001b[0m \u001b[0;31m#\u5de6\u4fa7mlp\u5bf9img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmlp_right\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_total_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmulti_AE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vis_txt\u001b[0m \u001b[0;31m#\u53f3\u4fa7mlp\u5bf9txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAssertionError\u001b[0m: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/pylearn2/models/mlp.py:41: UserWarning: MLP changing the recursion limit.\n",
        "  warnings.warn(\"MLP changing the recursion limit.\")\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}